{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOAOBMypAGJLsa4CmJR8gpK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/itsmeayushipanday/Chatbot-Using-Python-And-Machine-Learning/blob/main/Chatbot_Using_Python_And_Machine_Learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**DATA PREPARATION**"
      ],
      "metadata": {
        "id": "u0J_0CqXhv32"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "IMPORTING LIBRARIES"
      ],
      "metadata": {
        "id": "eAb6gWGIiCoc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Embedding, GlobalAveragePooling1D\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.preprocessing import LabelEncoder"
      ],
      "metadata": {
        "id": "8vtliu28iE3i"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "READ JSON FILE AND PROCESS THE REQUIRED FIELDS"
      ],
      "metadata": {
        "id": "of1VkEvYlMLD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open('intents.json') as file:\n",
        "    data = json.load(file)"
      ],
      "metadata": {
        "id": "eMryLJ99lP68"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#The labels list stores unique intent tags,\n",
        "#The training_sentences and training_labels lists are used for training the model.\n",
        "#The responses list stores possible responses for each intent.\n",
        "training_sentences = []\n",
        "training_labels = []\n",
        "labels = []\n",
        "responses = []"
      ],
      "metadata": {
        "id": "8hDl5slalT0p"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for intent in data['intents']:\n",
        "    for pattern in intent['patterns']:\n",
        "        training_sentences.append(pattern)\n",
        "        training_labels.append(intent['tag'])\n",
        "    responses.append(intent['responses'])\n",
        "\n",
        "    if intent['tag'] not in labels:\n",
        "        labels.append(intent['tag'])\n",
        "\n",
        "num_classes = len(labels)"
      ],
      "metadata": {
        "id": "E2dxfio5lZjN"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "LABEL ENCODER METHOD"
      ],
      "metadata": {
        "id": "T400Kis4nFG9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Label encoding initialization (to convert categorical labels into numerical labels)\n",
        "lbl_encoder = LabelEncoder()"
      ],
      "metadata": {
        "id": "S1kvdLovnHAd"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Fitting the encoder (to fit the encoder on the training_labels)\n",
        "lbl_encoder.fit(training_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "6_lI44pFnl_C",
        "outputId": "08a0db53-3344-4859-b573-430a77f73bf1"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LabelEncoder()"
            ],
            "text/html": [
              "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LabelEncoder()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LabelEncoder</label><div class=\"sk-toggleable__content\"><pre>LabelEncoder()</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Transforming labels (converts the original string-based labels in the training_labels list to corresponding numerical labels )\n",
        "training_labels = lbl_encoder.transform(training_labels)"
      ],
      "metadata": {
        "id": "Vlho_x98nzWi"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "TOKENIZATION (Used in natural language processing to split paragraphs and sentences into smaller units that can be more easily assigned meaning)"
      ],
      "metadata": {
        "id": "DBBl78RBoPCd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Setting parameters\n",
        "vocab_size = 1000\n",
        "embedding_dim = 16\n",
        "max_len = 20\n",
        "oov_token = \"<OOV>\""
      ],
      "metadata": {
        "id": "iHgi9seCoQNT"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Tokenizer initialization and fitting\n",
        "tokenizer = Tokenizer(num_words=vocab_size, oov_token=oov_token)\n",
        "tokenizer.fit_on_texts(training_sentences)"
      ],
      "metadata": {
        "id": "Pu1_93dcpI4E"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Word index (unique integer index assigned to each word based on its frequency in the training data)\n",
        "word_index = tokenizer.word_index"
      ],
      "metadata": {
        "id": "Ahuv_eRGpzef"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Converting Sentences to Sequences\n",
        "sequences = tokenizer.texts_to_sequences(training_sentences)"
      ],
      "metadata": {
        "id": "9Kq1rTjKqBo_"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Pdding sequences (to ensure that all sequences have the same length by padding them with zeros)\n",
        "padded_sequences = pad_sequences(sequences, truncating='post', maxlen=max_len)"
      ],
      "metadata": {
        "id": "-oiHaOf3qRs4"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "TRAINING A NEURAL NETWORK"
      ],
      "metadata": {
        "id": "43UbGTSPqzTT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(training_labels[:33])\n",
        "print(padded_sequences[:34])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C9nPquNZzPpa",
        "outputId": "338479a7-df80-4240-dfec-676942e3ae41"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[4 4 4 4 4 3 3 3 7 7 7 7 0 0 0 6 6 6 5 5 5 5 5 5 5 2 2 2 2 2 1 1 1]\n",
            "[[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 29]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 30]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 10 31 18]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 32]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 33]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 34]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 35  2 36]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 37]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 19]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 38  2]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 39 40]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 19 11 41  8]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 20 12  2]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  9 12  2]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 20  2 12]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  9 10 21 22]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  9 42  4 43  2]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 44 21 22]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 45  2  8  5]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 46  5  3 47 23]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 13  2  8]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  9 13  2 48 11  5]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  4 14  3 24]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  4 14  3  8]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 24  5 23]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  4 14  6 15  3 16  7]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0 25  6 26  3 16  7]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  4 27  6 15 28  7]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0 13  2 15 28  7 11  5]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0 25  6 26  3 16  7]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 49  3 17]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  4 27  6 50  3 17]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0 18 10  3 17 51  3 52]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"padded_sequences shape:\", padded_sequences.shape)\n",
        "print(\"training_labels shape:\", training_labels.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0FqZocc30txE",
        "outputId": "ded2cb5f-c9c0-4ca5-b914-a303e6eb2680"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "padded_sequences shape: (33, 20)\n",
            "training_labels shape: (33,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.api._v2.keras import activations\n",
        "#Creating the sequential model\n",
        "model = Sequential()\n",
        "\n",
        "#Adding layers to model\n",
        "model.add(Embedding(vocab_size, embedding_dim, input_length=max_len))\n",
        "model.add(GlobalAveragePooling1D()) #performs global average pooling over the temporal dimension of the sequence.\n",
        "model.add(Dense(16, activation='relu'))\n",
        "model.add(Dense(16, activation='relu'))"
      ],
      "metadata": {
        "id": "00D0kFz4q2Ut"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Output layer\n",
        "model.add(Dense(num_classes, activation='softmax'))"
      ],
      "metadata": {
        "id": "Wq1OJxigsSgG"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Compiling the Model\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SzPFWy6BsqoT",
        "outputId": "b898910a-510d-4a2c-b574-c0c621be7a14"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_2 (Embedding)     (None, 20, 16)            16000     \n",
            "                                                                 \n",
            " global_average_pooling1d_2   (None, 16)               0         \n",
            " (GlobalAveragePooling1D)                                        \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 16)                272       \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 16)                272       \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 8)                 136       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 16,680\n",
            "Trainable params: 16,680\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Length of padded_sequences:\", len(padded_sequences))\n",
        "print(\"Length of training_labels:\", len(training_labels))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vk4E-t1WtR7u",
        "outputId": "21ce96c5-ab78-4ec6-86de-e2a825315ead"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of padded_sequences: 33\n",
            "Length of training_labels: 33\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 500\n",
        "history = model.fit(padded_sequences, np.array(training_labels), epochs=epochs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a5rPYRyVtu8h",
        "outputId": "d20243ab-2a77-48ec-bf23-796192e7e924"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "2/2 [==============================] - 1s 12ms/step - loss: 2.0795 - accuracy: 0.1515\n",
            "Epoch 2/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 2.0783 - accuracy: 0.1515\n",
            "Epoch 3/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 2.0778 - accuracy: 0.1515\n",
            "Epoch 4/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 2.0771 - accuracy: 0.1515\n",
            "Epoch 5/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 2.0763 - accuracy: 0.1515\n",
            "Epoch 6/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 2.0757 - accuracy: 0.1515\n",
            "Epoch 7/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 2.0752 - accuracy: 0.1515\n",
            "Epoch 8/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 2.0747 - accuracy: 0.1515\n",
            "Epoch 9/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 2.0742 - accuracy: 0.1515\n",
            "Epoch 10/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 2.0738 - accuracy: 0.1515\n",
            "Epoch 11/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 2.0734 - accuracy: 0.1515\n",
            "Epoch 12/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 2.0731 - accuracy: 0.1515\n",
            "Epoch 13/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 2.0725 - accuracy: 0.1515\n",
            "Epoch 14/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 2.0718 - accuracy: 0.1515\n",
            "Epoch 15/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 2.0712 - accuracy: 0.1515\n",
            "Epoch 16/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 2.0705 - accuracy: 0.1515\n",
            "Epoch 17/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 2.0700 - accuracy: 0.1515\n",
            "Epoch 18/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 2.0695 - accuracy: 0.1515\n",
            "Epoch 19/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 2.0690 - accuracy: 0.1515\n",
            "Epoch 20/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 2.0684 - accuracy: 0.1515\n",
            "Epoch 21/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 2.0677 - accuracy: 0.1515\n",
            "Epoch 22/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 2.0670 - accuracy: 0.1515\n",
            "Epoch 23/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 2.0664 - accuracy: 0.1515\n",
            "Epoch 24/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 2.0658 - accuracy: 0.1515\n",
            "Epoch 25/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 2.0653 - accuracy: 0.1515\n",
            "Epoch 26/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 2.0648 - accuracy: 0.1515\n",
            "Epoch 27/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 2.0644 - accuracy: 0.1515\n",
            "Epoch 28/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 2.0639 - accuracy: 0.1515\n",
            "Epoch 29/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 2.0635 - accuracy: 0.1515\n",
            "Epoch 30/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 2.0632 - accuracy: 0.1515\n",
            "Epoch 31/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 2.0629 - accuracy: 0.1515\n",
            "Epoch 32/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 2.0625 - accuracy: 0.1515\n",
            "Epoch 33/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 2.0619 - accuracy: 0.1515\n",
            "Epoch 34/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 2.0613 - accuracy: 0.1515\n",
            "Epoch 35/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 2.0606 - accuracy: 0.1515\n",
            "Epoch 36/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 2.0601 - accuracy: 0.1515\n",
            "Epoch 37/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 2.0593 - accuracy: 0.1515\n",
            "Epoch 38/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 2.0587 - accuracy: 0.1515\n",
            "Epoch 39/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 2.0581 - accuracy: 0.1515\n",
            "Epoch 40/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 2.0574 - accuracy: 0.1515\n",
            "Epoch 41/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 2.0568 - accuracy: 0.1515\n",
            "Epoch 42/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 2.0562 - accuracy: 0.1515\n",
            "Epoch 43/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 2.0558 - accuracy: 0.1515\n",
            "Epoch 44/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 2.0556 - accuracy: 0.1515\n",
            "Epoch 45/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 2.0556 - accuracy: 0.1515\n",
            "Epoch 46/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 2.0554 - accuracy: 0.1515\n",
            "Epoch 47/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 2.0549 - accuracy: 0.1515\n",
            "Epoch 48/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 2.0541 - accuracy: 0.1515\n",
            "Epoch 49/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 2.0529 - accuracy: 0.1515\n",
            "Epoch 50/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 2.0517 - accuracy: 0.1515\n",
            "Epoch 51/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 2.0504 - accuracy: 0.1515\n",
            "Epoch 52/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 2.0488 - accuracy: 0.1515\n",
            "Epoch 53/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 2.0473 - accuracy: 0.1515\n",
            "Epoch 54/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 2.0458 - accuracy: 0.1515\n",
            "Epoch 55/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 2.0444 - accuracy: 0.1515\n",
            "Epoch 56/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 2.0429 - accuracy: 0.1515\n",
            "Epoch 57/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 2.0416 - accuracy: 0.1515\n",
            "Epoch 58/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 2.0404 - accuracy: 0.1515\n",
            "Epoch 59/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 2.0394 - accuracy: 0.1515\n",
            "Epoch 60/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 2.0382 - accuracy: 0.1515\n",
            "Epoch 61/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 2.0363 - accuracy: 0.1515\n",
            "Epoch 62/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 2.0341 - accuracy: 0.1515\n",
            "Epoch 63/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 2.0319 - accuracy: 0.1515\n",
            "Epoch 64/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 2.0299 - accuracy: 0.1515\n",
            "Epoch 65/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 2.0281 - accuracy: 0.1515\n",
            "Epoch 66/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 2.0263 - accuracy: 0.1515\n",
            "Epoch 67/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 2.0242 - accuracy: 0.1515\n",
            "Epoch 68/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 2.0223 - accuracy: 0.1515\n",
            "Epoch 69/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 2.0204 - accuracy: 0.1515\n",
            "Epoch 70/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 2.0188 - accuracy: 0.1515\n",
            "Epoch 71/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 2.0176 - accuracy: 0.1515\n",
            "Epoch 72/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 2.0166 - accuracy: 0.1515\n",
            "Epoch 73/500\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 2.0153 - accuracy: 0.1515\n",
            "Epoch 74/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 2.0143 - accuracy: 0.1515\n",
            "Epoch 75/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 2.0131 - accuracy: 0.1515\n",
            "Epoch 76/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 2.0117 - accuracy: 0.1515\n",
            "Epoch 77/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 2.0101 - accuracy: 0.1515\n",
            "Epoch 78/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 2.0095 - accuracy: 0.1515\n",
            "Epoch 79/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 2.0077 - accuracy: 0.1515\n",
            "Epoch 80/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 2.0068 - accuracy: 0.1515\n",
            "Epoch 81/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 2.0054 - accuracy: 0.1515\n",
            "Epoch 82/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 2.0038 - accuracy: 0.1515\n",
            "Epoch 83/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 2.0023 - accuracy: 0.1515\n",
            "Epoch 84/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 2.0006 - accuracy: 0.1515\n",
            "Epoch 85/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.9987 - accuracy: 0.1515\n",
            "Epoch 86/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 1.9971 - accuracy: 0.1515\n",
            "Epoch 87/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.9950 - accuracy: 0.1515\n",
            "Epoch 88/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 1.9927 - accuracy: 0.1515\n",
            "Epoch 89/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.9902 - accuracy: 0.1515\n",
            "Epoch 90/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 1.9877 - accuracy: 0.1515\n",
            "Epoch 91/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 1.9851 - accuracy: 0.1515\n",
            "Epoch 92/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.9824 - accuracy: 0.1515\n",
            "Epoch 93/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 1.9795 - accuracy: 0.1515\n",
            "Epoch 94/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 1.9770 - accuracy: 0.1515\n",
            "Epoch 95/500\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 1.9754 - accuracy: 0.1515\n",
            "Epoch 96/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 1.9735 - accuracy: 0.1515\n",
            "Epoch 97/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.9715 - accuracy: 0.1515\n",
            "Epoch 98/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.9695 - accuracy: 0.1515\n",
            "Epoch 99/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.9675 - accuracy: 0.1515\n",
            "Epoch 100/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.9652 - accuracy: 0.1515\n",
            "Epoch 101/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.9621 - accuracy: 0.1515\n",
            "Epoch 102/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.9591 - accuracy: 0.1515\n",
            "Epoch 103/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.9559 - accuracy: 0.1515\n",
            "Epoch 104/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.9530 - accuracy: 0.1515\n",
            "Epoch 105/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 1.9502 - accuracy: 0.1515\n",
            "Epoch 106/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 1.9474 - accuracy: 0.1515\n",
            "Epoch 107/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 1.9447 - accuracy: 0.1515\n",
            "Epoch 108/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.9417 - accuracy: 0.1515\n",
            "Epoch 109/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.9392 - accuracy: 0.1515\n",
            "Epoch 110/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.9366 - accuracy: 0.1515\n",
            "Epoch 111/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.9339 - accuracy: 0.1515\n",
            "Epoch 112/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.9313 - accuracy: 0.1515\n",
            "Epoch 113/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.9286 - accuracy: 0.1515\n",
            "Epoch 114/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.9260 - accuracy: 0.1515\n",
            "Epoch 115/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.9238 - accuracy: 0.1515\n",
            "Epoch 116/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.9214 - accuracy: 0.1515\n",
            "Epoch 117/500\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 1.9190 - accuracy: 0.1515\n",
            "Epoch 118/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 1.9166 - accuracy: 0.1515\n",
            "Epoch 119/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.9142 - accuracy: 0.1515\n",
            "Epoch 120/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.9114 - accuracy: 0.1515\n",
            "Epoch 121/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.9089 - accuracy: 0.1515\n",
            "Epoch 122/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.9065 - accuracy: 0.1515\n",
            "Epoch 123/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.9047 - accuracy: 0.1515\n",
            "Epoch 124/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.9033 - accuracy: 0.1515\n",
            "Epoch 125/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.9017 - accuracy: 0.1515\n",
            "Epoch 126/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.9003 - accuracy: 0.1515\n",
            "Epoch 127/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.8988 - accuracy: 0.1515\n",
            "Epoch 128/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 1.8975 - accuracy: 0.1515\n",
            "Epoch 129/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.8962 - accuracy: 0.1818\n",
            "Epoch 130/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.8946 - accuracy: 0.1818\n",
            "Epoch 131/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.8926 - accuracy: 0.1818\n",
            "Epoch 132/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 1.8905 - accuracy: 0.1818\n",
            "Epoch 133/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.8882 - accuracy: 0.1818\n",
            "Epoch 134/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.8859 - accuracy: 0.1818\n",
            "Epoch 135/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.8835 - accuracy: 0.1818\n",
            "Epoch 136/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.8798 - accuracy: 0.1515\n",
            "Epoch 137/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.8756 - accuracy: 0.1515\n",
            "Epoch 138/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.8719 - accuracy: 0.1515\n",
            "Epoch 139/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.8702 - accuracy: 0.1515\n",
            "Epoch 140/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 1.8678 - accuracy: 0.1515\n",
            "Epoch 141/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.8678 - accuracy: 0.1515\n",
            "Epoch 142/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 1.8667 - accuracy: 0.1515\n",
            "Epoch 143/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 1.8625 - accuracy: 0.1515\n",
            "Epoch 144/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 1.8566 - accuracy: 0.1515\n",
            "Epoch 145/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.8511 - accuracy: 0.1515\n",
            "Epoch 146/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.8463 - accuracy: 0.1515\n",
            "Epoch 147/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.8414 - accuracy: 0.1515\n",
            "Epoch 148/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.8365 - accuracy: 0.1515\n",
            "Epoch 149/500\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 1.8326 - accuracy: 0.1515\n",
            "Epoch 150/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 1.8299 - accuracy: 0.1515\n",
            "Epoch 151/500\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 1.8284 - accuracy: 0.1515\n",
            "Epoch 152/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 1.8269 - accuracy: 0.1515\n",
            "Epoch 153/500\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 1.8254 - accuracy: 0.1515\n",
            "Epoch 154/500\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 1.8237 - accuracy: 0.1515\n",
            "Epoch 155/500\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 1.8218 - accuracy: 0.1515\n",
            "Epoch 156/500\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 1.8200 - accuracy: 0.1515\n",
            "Epoch 157/500\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 1.8180 - accuracy: 0.1515\n",
            "Epoch 158/500\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 1.8161 - accuracy: 0.1818\n",
            "Epoch 159/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 1.8130 - accuracy: 0.1515\n",
            "Epoch 160/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 1.8084 - accuracy: 0.1515\n",
            "Epoch 161/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 1.8041 - accuracy: 0.1515\n",
            "Epoch 162/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 1.8005 - accuracy: 0.1818\n",
            "Epoch 163/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 1.7969 - accuracy: 0.1818\n",
            "Epoch 164/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 1.7938 - accuracy: 0.1818\n",
            "Epoch 165/500\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 1.7909 - accuracy: 0.1818\n",
            "Epoch 166/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.7879 - accuracy: 0.1818\n",
            "Epoch 167/500\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 1.7844 - accuracy: 0.1818\n",
            "Epoch 168/500\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 1.7816 - accuracy: 0.1818\n",
            "Epoch 169/500\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 1.7791 - accuracy: 0.1818\n",
            "Epoch 170/500\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 1.7767 - accuracy: 0.1818\n",
            "Epoch 171/500\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 1.7747 - accuracy: 0.1818\n",
            "Epoch 172/500\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 1.7724 - accuracy: 0.1818\n",
            "Epoch 173/500\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 1.7698 - accuracy: 0.1515\n",
            "Epoch 174/500\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 1.7675 - accuracy: 0.1515\n",
            "Epoch 175/500\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 1.7648 - accuracy: 0.1515\n",
            "Epoch 176/500\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 1.7616 - accuracy: 0.1515\n",
            "Epoch 177/500\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 1.7586 - accuracy: 0.1515\n",
            "Epoch 178/500\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 1.7553 - accuracy: 0.1515\n",
            "Epoch 179/500\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 1.7522 - accuracy: 0.1515\n",
            "Epoch 180/500\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 1.7495 - accuracy: 0.1515\n",
            "Epoch 181/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 1.7472 - accuracy: 0.1818\n",
            "Epoch 182/500\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 1.7448 - accuracy: 0.1818\n",
            "Epoch 183/500\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 1.7420 - accuracy: 0.1818\n",
            "Epoch 184/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 1.7393 - accuracy: 0.1515\n",
            "Epoch 185/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.7362 - accuracy: 0.1515\n",
            "Epoch 186/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.7332 - accuracy: 0.1515\n",
            "Epoch 187/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.7304 - accuracy: 0.1515\n",
            "Epoch 188/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.7274 - accuracy: 0.1515\n",
            "Epoch 189/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.7246 - accuracy: 0.1515\n",
            "Epoch 190/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 1.7220 - accuracy: 0.1818\n",
            "Epoch 191/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.7194 - accuracy: 0.1818\n",
            "Epoch 192/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.7169 - accuracy: 0.1818\n",
            "Epoch 193/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.7145 - accuracy: 0.1818\n",
            "Epoch 194/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.7128 - accuracy: 0.2121\n",
            "Epoch 195/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.7120 - accuracy: 0.2121\n",
            "Epoch 196/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.7118 - accuracy: 0.2727\n",
            "Epoch 197/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.7107 - accuracy: 0.3030\n",
            "Epoch 198/500\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 1.7086 - accuracy: 0.3030\n",
            "Epoch 199/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.7059 - accuracy: 0.3030\n",
            "Epoch 200/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.7029 - accuracy: 0.3030\n",
            "Epoch 201/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 1.7000 - accuracy: 0.3030\n",
            "Epoch 202/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.6972 - accuracy: 0.3030\n",
            "Epoch 203/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.6942 - accuracy: 0.2727\n",
            "Epoch 204/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.6911 - accuracy: 0.2121\n",
            "Epoch 205/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.6881 - accuracy: 0.2121\n",
            "Epoch 206/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 1.6854 - accuracy: 0.2121\n",
            "Epoch 207/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 1.6828 - accuracy: 0.2121\n",
            "Epoch 208/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 1.6802 - accuracy: 0.2121\n",
            "Epoch 209/500\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 1.6778 - accuracy: 0.1818\n",
            "Epoch 210/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 1.6755 - accuracy: 0.1818\n",
            "Epoch 211/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 1.6729 - accuracy: 0.1818\n",
            "Epoch 212/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.6699 - accuracy: 0.1818\n",
            "Epoch 213/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 1.6665 - accuracy: 0.2121\n",
            "Epoch 214/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.6636 - accuracy: 0.1818\n",
            "Epoch 215/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 1.6611 - accuracy: 0.2121\n",
            "Epoch 216/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 1.6587 - accuracy: 0.1818\n",
            "Epoch 217/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 1.6565 - accuracy: 0.1818\n",
            "Epoch 218/500\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 1.6543 - accuracy: 0.1818\n",
            "Epoch 219/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.6523 - accuracy: 0.1818\n",
            "Epoch 220/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.6500 - accuracy: 0.1818\n",
            "Epoch 221/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.6476 - accuracy: 0.2424\n",
            "Epoch 222/500\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 1.6454 - accuracy: 0.2424\n",
            "Epoch 223/500\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 1.6434 - accuracy: 0.2424\n",
            "Epoch 224/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.6415 - accuracy: 0.2121\n",
            "Epoch 225/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 1.6399 - accuracy: 0.2121\n",
            "Epoch 226/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 1.6381 - accuracy: 0.2121\n",
            "Epoch 227/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 1.6359 - accuracy: 0.2121\n",
            "Epoch 228/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 1.6329 - accuracy: 0.2121\n",
            "Epoch 229/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 1.6294 - accuracy: 0.2121\n",
            "Epoch 230/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 1.6258 - accuracy: 0.2424\n",
            "Epoch 231/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.6224 - accuracy: 0.2424\n",
            "Epoch 232/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.6186 - accuracy: 0.2727\n",
            "Epoch 233/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.6155 - accuracy: 0.2727\n",
            "Epoch 234/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.6129 - accuracy: 0.2424\n",
            "Epoch 235/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.6104 - accuracy: 0.2121\n",
            "Epoch 236/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.6078 - accuracy: 0.2121\n",
            "Epoch 237/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.6045 - accuracy: 0.2727\n",
            "Epoch 238/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.6011 - accuracy: 0.2727\n",
            "Epoch 239/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.5984 - accuracy: 0.3333\n",
            "Epoch 240/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 1.5963 - accuracy: 0.3333\n",
            "Epoch 241/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.5944 - accuracy: 0.3636\n",
            "Epoch 242/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 1.5919 - accuracy: 0.3636\n",
            "Epoch 243/500\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 1.5889 - accuracy: 0.3636\n",
            "Epoch 244/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.5858 - accuracy: 0.3636\n",
            "Epoch 245/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 1.5828 - accuracy: 0.3636\n",
            "Epoch 246/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.5799 - accuracy: 0.3636\n",
            "Epoch 247/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 1.5774 - accuracy: 0.3636\n",
            "Epoch 248/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.5748 - accuracy: 0.3636\n",
            "Epoch 249/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 1.5722 - accuracy: 0.3636\n",
            "Epoch 250/500\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 1.5697 - accuracy: 0.3636\n",
            "Epoch 251/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 1.5667 - accuracy: 0.3636\n",
            "Epoch 252/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.5637 - accuracy: 0.3636\n",
            "Epoch 253/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.5601 - accuracy: 0.3636\n",
            "Epoch 254/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.5569 - accuracy: 0.3636\n",
            "Epoch 255/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.5538 - accuracy: 0.3636\n",
            "Epoch 256/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.5510 - accuracy: 0.3636\n",
            "Epoch 257/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.5488 - accuracy: 0.3636\n",
            "Epoch 258/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.5463 - accuracy: 0.3636\n",
            "Epoch 259/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.5426 - accuracy: 0.3636\n",
            "Epoch 260/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.5387 - accuracy: 0.3636\n",
            "Epoch 261/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 1.5347 - accuracy: 0.3636\n",
            "Epoch 262/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.5312 - accuracy: 0.3636\n",
            "Epoch 263/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 1.5285 - accuracy: 0.3636\n",
            "Epoch 264/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.5253 - accuracy: 0.3636\n",
            "Epoch 265/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.5218 - accuracy: 0.3636\n",
            "Epoch 266/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 1.5191 - accuracy: 0.3636\n",
            "Epoch 267/500\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 1.5147 - accuracy: 0.3636\n",
            "Epoch 268/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 1.5113 - accuracy: 0.4242\n",
            "Epoch 269/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 1.5086 - accuracy: 0.4242\n",
            "Epoch 270/500\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 1.5053 - accuracy: 0.4242\n",
            "Epoch 271/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 1.5010 - accuracy: 0.4242\n",
            "Epoch 272/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 1.4975 - accuracy: 0.4242\n",
            "Epoch 273/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 1.4948 - accuracy: 0.4242\n",
            "Epoch 274/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 1.4920 - accuracy: 0.4242\n",
            "Epoch 275/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 1.4883 - accuracy: 0.4242\n",
            "Epoch 276/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.4847 - accuracy: 0.4242\n",
            "Epoch 277/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.4818 - accuracy: 0.4242\n",
            "Epoch 278/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.4791 - accuracy: 0.4242\n",
            "Epoch 279/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.4764 - accuracy: 0.4242\n",
            "Epoch 280/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.4741 - accuracy: 0.4242\n",
            "Epoch 281/500\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 1.4717 - accuracy: 0.4242\n",
            "Epoch 282/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.4693 - accuracy: 0.4242\n",
            "Epoch 283/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.4666 - accuracy: 0.4242\n",
            "Epoch 284/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.4636 - accuracy: 0.4242\n",
            "Epoch 285/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.4604 - accuracy: 0.4242\n",
            "Epoch 286/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.4573 - accuracy: 0.4242\n",
            "Epoch 287/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.4543 - accuracy: 0.4242\n",
            "Epoch 288/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.4514 - accuracy: 0.4242\n",
            "Epoch 289/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.4487 - accuracy: 0.4242\n",
            "Epoch 290/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 1.4461 - accuracy: 0.4242\n",
            "Epoch 291/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.4436 - accuracy: 0.4242\n",
            "Epoch 292/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 1.4414 - accuracy: 0.4242\n",
            "Epoch 293/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 1.4392 - accuracy: 0.4242\n",
            "Epoch 294/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.4374 - accuracy: 0.4242\n",
            "Epoch 295/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 1.4351 - accuracy: 0.4242\n",
            "Epoch 296/500\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 1.4322 - accuracy: 0.4242\n",
            "Epoch 297/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 1.4293 - accuracy: 0.4242\n",
            "Epoch 298/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.4255 - accuracy: 0.4242\n",
            "Epoch 299/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 1.4219 - accuracy: 0.4242\n",
            "Epoch 300/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 1.4185 - accuracy: 0.4242\n",
            "Epoch 301/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.4153 - accuracy: 0.4242\n",
            "Epoch 302/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 1.4120 - accuracy: 0.4242\n",
            "Epoch 303/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 1.4089 - accuracy: 0.4242\n",
            "Epoch 304/500\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 1.4053 - accuracy: 0.4242\n",
            "Epoch 305/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 1.4018 - accuracy: 0.4242\n",
            "Epoch 306/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 1.3982 - accuracy: 0.4242\n",
            "Epoch 307/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 1.3942 - accuracy: 0.4242\n",
            "Epoch 308/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 1.3901 - accuracy: 0.4242\n",
            "Epoch 309/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 1.3862 - accuracy: 0.4242\n",
            "Epoch 310/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.3826 - accuracy: 0.4242\n",
            "Epoch 311/500\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 1.3788 - accuracy: 0.4242\n",
            "Epoch 312/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 1.3748 - accuracy: 0.4242\n",
            "Epoch 313/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.3717 - accuracy: 0.5152\n",
            "Epoch 314/500\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 1.3696 - accuracy: 0.5152\n",
            "Epoch 315/500\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 1.3673 - accuracy: 0.5152\n",
            "Epoch 316/500\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 1.3638 - accuracy: 0.5152\n",
            "Epoch 317/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 1.3599 - accuracy: 0.5152\n",
            "Epoch 318/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 1.3556 - accuracy: 0.5152\n",
            "Epoch 319/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.3521 - accuracy: 0.5152\n",
            "Epoch 320/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.3481 - accuracy: 0.4848\n",
            "Epoch 321/500\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 1.3427 - accuracy: 0.5152\n",
            "Epoch 322/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 1.3372 - accuracy: 0.5152\n",
            "Epoch 323/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.3325 - accuracy: 0.5152\n",
            "Epoch 324/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 1.3287 - accuracy: 0.5152\n",
            "Epoch 325/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 1.3244 - accuracy: 0.5152\n",
            "Epoch 326/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 1.3196 - accuracy: 0.5152\n",
            "Epoch 327/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 1.3152 - accuracy: 0.5152\n",
            "Epoch 328/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.3109 - accuracy: 0.5455\n",
            "Epoch 329/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.3068 - accuracy: 0.6061\n",
            "Epoch 330/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.3027 - accuracy: 0.6061\n",
            "Epoch 331/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.2986 - accuracy: 0.6061\n",
            "Epoch 332/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.2954 - accuracy: 0.6061\n",
            "Epoch 333/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.2924 - accuracy: 0.6061\n",
            "Epoch 334/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.2900 - accuracy: 0.6061\n",
            "Epoch 335/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 1.2871 - accuracy: 0.6061\n",
            "Epoch 336/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.2833 - accuracy: 0.6061\n",
            "Epoch 337/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.2800 - accuracy: 0.6061\n",
            "Epoch 338/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.2754 - accuracy: 0.6061\n",
            "Epoch 339/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.2708 - accuracy: 0.6061\n",
            "Epoch 340/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.2656 - accuracy: 0.6061\n",
            "Epoch 341/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.2591 - accuracy: 0.6061\n",
            "Epoch 342/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.2533 - accuracy: 0.6061\n",
            "Epoch 343/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.2474 - accuracy: 0.6061\n",
            "Epoch 344/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.2428 - accuracy: 0.6061\n",
            "Epoch 345/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.2386 - accuracy: 0.6061\n",
            "Epoch 346/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.2364 - accuracy: 0.6061\n",
            "Epoch 347/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.2337 - accuracy: 0.6061\n",
            "Epoch 348/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.2294 - accuracy: 0.6061\n",
            "Epoch 349/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.2239 - accuracy: 0.6061\n",
            "Epoch 350/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.2188 - accuracy: 0.6061\n",
            "Epoch 351/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.2148 - accuracy: 0.6364\n",
            "Epoch 352/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.2104 - accuracy: 0.6364\n",
            "Epoch 353/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.2067 - accuracy: 0.5758\n",
            "Epoch 354/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.2018 - accuracy: 0.5758\n",
            "Epoch 355/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.1970 - accuracy: 0.6667\n",
            "Epoch 356/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.1930 - accuracy: 0.6667\n",
            "Epoch 357/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.1891 - accuracy: 0.5758\n",
            "Epoch 358/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.1853 - accuracy: 0.6061\n",
            "Epoch 359/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.1821 - accuracy: 0.6061\n",
            "Epoch 360/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.1781 - accuracy: 0.6061\n",
            "Epoch 361/500\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 1.1733 - accuracy: 0.6061\n",
            "Epoch 362/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 1.1691 - accuracy: 0.6061\n",
            "Epoch 363/500\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 1.1652 - accuracy: 0.6061\n",
            "Epoch 364/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 1.1607 - accuracy: 0.6061\n",
            "Epoch 365/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.1566 - accuracy: 0.6061\n",
            "Epoch 366/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 1.1533 - accuracy: 0.6061\n",
            "Epoch 367/500\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 1.1499 - accuracy: 0.6061\n",
            "Epoch 368/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 1.1470 - accuracy: 0.6061\n",
            "Epoch 369/500\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 1.1445 - accuracy: 0.6061\n",
            "Epoch 370/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.1414 - accuracy: 0.6061\n",
            "Epoch 371/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.1378 - accuracy: 0.6061\n",
            "Epoch 372/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 1.1339 - accuracy: 0.6061\n",
            "Epoch 373/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.1303 - accuracy: 0.6061\n",
            "Epoch 374/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 1.1267 - accuracy: 0.6061\n",
            "Epoch 375/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.1208 - accuracy: 0.6061\n",
            "Epoch 376/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 1.1129 - accuracy: 0.6061\n",
            "Epoch 377/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 1.1075 - accuracy: 0.6061\n",
            "Epoch 378/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.1046 - accuracy: 0.6061\n",
            "Epoch 379/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.1008 - accuracy: 0.6061\n",
            "Epoch 380/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.0952 - accuracy: 0.6061\n",
            "Epoch 381/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 1.0922 - accuracy: 0.6061\n",
            "Epoch 382/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 1.0896 - accuracy: 0.6061\n",
            "Epoch 383/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 1.0865 - accuracy: 0.6364\n",
            "Epoch 384/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.0830 - accuracy: 0.6364\n",
            "Epoch 385/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.0795 - accuracy: 0.6364\n",
            "Epoch 386/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.0757 - accuracy: 0.6364\n",
            "Epoch 387/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 1.0723 - accuracy: 0.6364\n",
            "Epoch 388/500\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 1.0695 - accuracy: 0.6364\n",
            "Epoch 389/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 1.0662 - accuracy: 0.6061\n",
            "Epoch 390/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.0630 - accuracy: 0.6970\n",
            "Epoch 391/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.0605 - accuracy: 0.6970\n",
            "Epoch 392/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.0582 - accuracy: 0.6970\n",
            "Epoch 393/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.0560 - accuracy: 0.6970\n",
            "Epoch 394/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.0529 - accuracy: 0.6970\n",
            "Epoch 395/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.0491 - accuracy: 0.6970\n",
            "Epoch 396/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.0447 - accuracy: 0.6970\n",
            "Epoch 397/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.0391 - accuracy: 0.6970\n",
            "Epoch 398/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.0334 - accuracy: 0.6970\n",
            "Epoch 399/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.0286 - accuracy: 0.6970\n",
            "Epoch 400/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.0251 - accuracy: 0.6667\n",
            "Epoch 401/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 1.0225 - accuracy: 0.6364\n",
            "Epoch 402/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.0214 - accuracy: 0.6364\n",
            "Epoch 403/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.0202 - accuracy: 0.6364\n",
            "Epoch 404/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.0188 - accuracy: 0.6364\n",
            "Epoch 405/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.0187 - accuracy: 0.6364\n",
            "Epoch 406/500\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 1.0157 - accuracy: 0.6364\n",
            "Epoch 407/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 1.0103 - accuracy: 0.6364\n",
            "Epoch 408/500\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 1.0047 - accuracy: 0.6364\n",
            "Epoch 409/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.9987 - accuracy: 0.6364\n",
            "Epoch 410/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.9929 - accuracy: 0.6364\n",
            "Epoch 411/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.9870 - accuracy: 0.6364\n",
            "Epoch 412/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.9810 - accuracy: 0.6364\n",
            "Epoch 413/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.9763 - accuracy: 0.6364\n",
            "Epoch 414/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.9726 - accuracy: 0.6364\n",
            "Epoch 415/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.9684 - accuracy: 0.6667\n",
            "Epoch 416/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.9631 - accuracy: 0.6667\n",
            "Epoch 417/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.9579 - accuracy: 0.6667\n",
            "Epoch 418/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.9548 - accuracy: 0.6667\n",
            "Epoch 419/500\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.9508 - accuracy: 0.6667\n",
            "Epoch 420/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.9466 - accuracy: 0.6667\n",
            "Epoch 421/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.9420 - accuracy: 0.6667\n",
            "Epoch 422/500\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 0.9381 - accuracy: 0.6667\n",
            "Epoch 423/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.9346 - accuracy: 0.6667\n",
            "Epoch 424/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.9316 - accuracy: 0.6667\n",
            "Epoch 425/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.9289 - accuracy: 0.6667\n",
            "Epoch 426/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.9261 - accuracy: 0.6667\n",
            "Epoch 427/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.9229 - accuracy: 0.6667\n",
            "Epoch 428/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.9182 - accuracy: 0.6667\n",
            "Epoch 429/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.9130 - accuracy: 0.6970\n",
            "Epoch 430/500\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.9095 - accuracy: 0.7273\n",
            "Epoch 431/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.9065 - accuracy: 0.7273\n",
            "Epoch 432/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.9039 - accuracy: 0.7273\n",
            "Epoch 433/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.9016 - accuracy: 0.7576\n",
            "Epoch 434/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.8992 - accuracy: 0.7576\n",
            "Epoch 435/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.8966 - accuracy: 0.7576\n",
            "Epoch 436/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.8934 - accuracy: 0.7576\n",
            "Epoch 437/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.8883 - accuracy: 0.7576\n",
            "Epoch 438/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.8831 - accuracy: 0.7576\n",
            "Epoch 439/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.8791 - accuracy: 0.7576\n",
            "Epoch 440/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.8754 - accuracy: 0.7576\n",
            "Epoch 441/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.8716 - accuracy: 0.7576\n",
            "Epoch 442/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.8674 - accuracy: 0.7576\n",
            "Epoch 443/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.8637 - accuracy: 0.7576\n",
            "Epoch 444/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.8604 - accuracy: 0.7576\n",
            "Epoch 445/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.8573 - accuracy: 0.7879\n",
            "Epoch 446/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.8545 - accuracy: 0.6970\n",
            "Epoch 447/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.8513 - accuracy: 0.6970\n",
            "Epoch 448/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.8487 - accuracy: 0.6970\n",
            "Epoch 449/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.8465 - accuracy: 0.6970\n",
            "Epoch 450/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.8445 - accuracy: 0.6970\n",
            "Epoch 451/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.8408 - accuracy: 0.6970\n",
            "Epoch 452/500\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 0.8366 - accuracy: 0.6970\n",
            "Epoch 453/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.8326 - accuracy: 0.6970\n",
            "Epoch 454/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.8287 - accuracy: 0.6970\n",
            "Epoch 455/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.8247 - accuracy: 0.7576\n",
            "Epoch 456/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.8214 - accuracy: 0.7576\n",
            "Epoch 457/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.8180 - accuracy: 0.7576\n",
            "Epoch 458/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.8141 - accuracy: 0.7576\n",
            "Epoch 459/500\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 0.8103 - accuracy: 0.7576\n",
            "Epoch 460/500\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.8078 - accuracy: 0.7576\n",
            "Epoch 461/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.8052 - accuracy: 0.7879\n",
            "Epoch 462/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.8034 - accuracy: 0.8182\n",
            "Epoch 463/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.8023 - accuracy: 0.8788\n",
            "Epoch 464/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.8017 - accuracy: 0.8788\n",
            "Epoch 465/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.8008 - accuracy: 0.8788\n",
            "Epoch 466/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.7996 - accuracy: 0.8485\n",
            "Epoch 467/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.7943 - accuracy: 0.8485\n",
            "Epoch 468/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.7872 - accuracy: 0.7879\n",
            "Epoch 469/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.7834 - accuracy: 0.7879\n",
            "Epoch 470/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.7803 - accuracy: 0.7576\n",
            "Epoch 471/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.7786 - accuracy: 0.7273\n",
            "Epoch 472/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.7778 - accuracy: 0.7273\n",
            "Epoch 473/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.7761 - accuracy: 0.6970\n",
            "Epoch 474/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.7724 - accuracy: 0.6970\n",
            "Epoch 475/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.7673 - accuracy: 0.7273\n",
            "Epoch 476/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.7628 - accuracy: 0.7576\n",
            "Epoch 477/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.7590 - accuracy: 0.7576\n",
            "Epoch 478/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.7568 - accuracy: 0.7576\n",
            "Epoch 479/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.7548 - accuracy: 0.7879\n",
            "Epoch 480/500\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.7506 - accuracy: 0.7879\n",
            "Epoch 481/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.7475 - accuracy: 0.8182\n",
            "Epoch 482/500\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 0.7444 - accuracy: 0.8182\n",
            "Epoch 483/500\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.7407 - accuracy: 0.8182\n",
            "Epoch 484/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.7381 - accuracy: 0.7879\n",
            "Epoch 485/500\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.7355 - accuracy: 0.7879\n",
            "Epoch 486/500\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.7330 - accuracy: 0.7879\n",
            "Epoch 487/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.7313 - accuracy: 0.7576\n",
            "Epoch 488/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.7296 - accuracy: 0.7576\n",
            "Epoch 489/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.7293 - accuracy: 0.7576\n",
            "Epoch 490/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.7284 - accuracy: 0.7576\n",
            "Epoch 491/500\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.7267 - accuracy: 0.7576\n",
            "Epoch 492/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.7238 - accuracy: 0.7576\n",
            "Epoch 493/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.7199 - accuracy: 0.7576\n",
            "Epoch 494/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.7157 - accuracy: 0.7576\n",
            "Epoch 495/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.7120 - accuracy: 0.7576\n",
            "Epoch 496/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.7094 - accuracy: 0.7576\n",
            "Epoch 497/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.7066 - accuracy: 0.7879\n",
            "Epoch 498/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.7040 - accuracy: 0.8182\n",
            "Epoch 499/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.7015 - accuracy: 0.8182\n",
            "Epoch 500/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.6994 - accuracy: 0.8485\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "SAVING THE MODEL FOR FUTURE USE"
      ],
      "metadata": {
        "id": "9Whcu1HQ5mXg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#To save the trained model\n",
        "model.save(\"chat_model\")\n",
        "\n",
        "import pickle\n",
        "#To save the fitted tokenizer\n",
        "with open('tokenizer.pickle', 'wb') as handle:\n",
        "    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "#To save the fitted label encoder\n",
        "with open('label_encoder.pickle', 'wb') as ecn_file:\n",
        "    pickle.dump(lbl_encoder, ecn_file, protocol=pickle.HIGHEST_PROTOCOL)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3P6rdbaE5pYC",
        "outputId": "1fe0dd95-0834-42e3-e9c6-391767134992"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "READY TO BUILD A CHATBOT WITH PYTHON AND OUR TRAINED MACHINE LEARNING MODEL"
      ],
      "metadata": {
        "id": "Fp_5LLjX7L-7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Import Libraries:\n",
        "import json\n",
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "\n",
        "!pip install --upgrade colorama\n",
        "import colorama\n",
        "colorama.init()\n",
        "from colorama import Fore, Style, Back\n",
        "\n",
        "import random\n",
        "import pickle"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dtUPNRGy7Sw6",
        "outputId": "9817f663-bc67-472c-f204-f98a8e72b2cf"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: colorama in /usr/local/lib/python3.10/dist-packages (0.4.6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y"
      ],
      "metadata": {
        "id": "jqyR_lXwB6qy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Load Intent Data\n",
        "with open(\"intents.json\") as file:\n",
        "  data = json.load(file)"
      ],
      "metadata": {
        "id": "UlwowXUR7rgQ"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Define the chat Function\n",
        "def chat():\n",
        "\n",
        "  # Load trained model\n",
        "  model = keras.models.load_model('chat_model')\n",
        "\n",
        "  # Load tokenizer object\n",
        "  with open('tokenizer.pickle', 'rb') as handle:\n",
        "    tockenizer = pickle.load(handle)\n",
        "\n",
        "  # Load label encoder object\n",
        "  with open('label_encoder.pickle', 'rb') as enc:\n",
        "    lbl_encoder = pickle.load(enc)\n",
        "\n",
        "  #parameters\n",
        "  max_len = 20\n",
        "\n",
        "  while True:\n",
        "    print(Fore.LIGHTBLUE_EX + \"User: \" + Style.RESET_ALL, end=\"\")\n",
        "    inp = input()\n",
        "    if inp.lower() == \"quit\":\n",
        "      break\n",
        "\n",
        "    result = model.predict(keras.preprocessing.sequence.pad_sequences(tokenizer.texts_to_sequences([inp]),\n",
        "                                             truncating='post', maxlen=max_len))\n",
        "    tag = lbl_encoder.inverse_transform([np.argmax(result)])\n",
        "\n",
        "    for i in data['intents']:\n",
        "      if i['tag'] == tag:\n",
        "        print(Fore.GREEN + \"ChatBot:\" + Style.RESET_ALL , np.random.choice(i['responses']))\n",
        "\n",
        "\n",
        "print(Fore.YELLOW + \"Start messaging with the bot (type quit to stop)!\" + Style.RESET_ALL)\n",
        "chat()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ScUA1ooX8mBP",
        "outputId": "e3eede8b-f01b-412f-f76e-75f4d8e36eb0"
      },
      "execution_count": 79,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Start messaging with the bot (type quit to stop)!\n",
            "User: Hi\n",
            "1/1 [==============================] - 0s 129ms/step\n",
            "ChatBot: Hi\n",
            "User: who are you\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "ChatBot: I.m Joana, your bot assistant\n",
            "User: what is your name\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "ChatBot: I.m Joana, your bot assistant\n",
            "User: i need your help\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "ChatBot: Tell me how can assist you\n",
            "User: i want to create an account\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "ChatBot: You can just easily create a new account from our web site\n",
            "User: i have a complaint\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "ChatBot: Please mention your complaint, we will reach you and sorry for any inconvenience caused\n",
            "User: you are so humble\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "ChatBot: My pleasure\n",
            "User: happy to contact you\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "ChatBot: Yes Sure, How can I support you\n",
            "User: i will contact you when i need your help\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "ChatBot: Yes Sure, How can I support you\n",
            "User: bye\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "ChatBot: Hi there\n",
            "User: quit\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UvNnI5Rc-Yzu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}